# Scheduling
Serve se ci sono più richiedenti che vogliono accedre ad una risorsa. Ad esempio i processi vogliono la CPU, oppure i processi vogliono i dischi.

L'algoritmo di scheduling sceglie a quale richiedente assegnare la risorsa. 

## Esempio
Immaginiamo due task o job.
A porta via 50 ms
B porta via 450ms

Se mando AB, A ci mette 50 per terminare, B termina a 500, Tempo medio di complementamento = 500+50/2
Se mando BA, A ci mette 500 per terminare e B 450. Tempo medio = 950/2

Misurare T di completamento medio. 
Possiamo voler minimizzare il tempo di attesa medio. il primo ha tempo di attesa 0, il secondo TComp(primo) etc
Minimizzare il tempo di risposta, uguale al tempo di attesa se non c'è frammentazione altrimenti no

Vogliamo massimizzare l'utilizzo CPU e il throughput

## Algoritmi di scheduling
Prima grande macro divisione
* Preemptive, il sistema operativo può sospendere l'esecuzione di un task o di un job
* Non-preemptive, il sistema operativo puo' sospendere solo in certi casi speciali

### First Come First Serve
I task vengono serviti in ordine di arrivi. Molto semplice da implementare. Non è per nulla ottimale. Non è pre-empitve e quindi ci sono ci sono tutti i problemi collegati.

### Shortest Job First
Viene eseguito il più breve prima. Ma non è implementabile. Per sapere quale è lo shortest job dovrei averlo eseguito, ma se non lo ho eseguito come faccio a sapere quanto ci mette il job? Lo posso usare solo se so già. Viene usato come benchmakr, confronto vs questo algoritmo.

### Round Robin / Time Slicing
Si basa sull'idea che a ciascun job do un quanto temporale e se non completa nel tempo il job torna in coda. Ci sono degli svantaggi: non è efficiente. Un quanto temporale troppo grande mi potrebbe diminuire la responsività dei processi più brevi e assomiglia quasi al FCFS. Se il quanto è molto piccolo devo continuare a switchare e diventa "Processor Sharing"

### L'algoritmo PRIority
Ogni job ha una priorità. Prima chi ha la priorità.


#### Esempio

P1 = 4t, 2P
P2 = 3t, 1P
P3 = 6t, 0P

Vediamo come vengono eseguiti sotto i vari scheduler. 

**FCFS**
P1 -> P2 -> P3
Tempo di attesa per P1 = 0t; P2=4t, P3=7t Tm=11/3=3,67t
Tempo di completamento P1=4t P2=7t P3=13t Tmc=24/3=8

**Shortest Job First**
P2 -> P1 -> P3
Tempo di attesa per P1=3t; P2=0t; P3=7t Tm=10/3=3,3333
Tempo di completamento P1=7t P2=3t P3=13t Tmc=23/3


**Round Robin**
Quanto = 2
P1 -> P2 -> P3 -> P1 (completa) -> P2 (completa in 1step) -> P3 -> P3 (completa)

Tempo di completamento
P1 = 8
P2 = 9
P3 = 13
Tcm = 30/3 = 10t

Tempi di risposta
P1 = 0t
P2 = 2t
P3 = 4t
TrispMedio = 2t

Tempo di attesa (somma di tutti i tempi morti per il processo 1)
P1 = 2t
P2 = 2+4t
P3 = 7


## Priorità

Fisse o variabili

Se un processo era in attesa da tanto gli alzo la priortà cosi si esegue ASAP

### Priorità multilivello
Divido i job in classi e ogni classe si gestisce al suo interno. Avrò un algoritmo che gestice quale classe eseguire.

Ad esempio ho Job Interattivi, Job del sistema operativo, Job in background. I job interattivi li gestisco in round robin ad esempio. La coda del sistema operativo lo gestisco con un sistema di priorità assoluta. Il background lo facciamo ad esempio FCFS. Queste tre code le gesisco in modo da allocare come voglio le risorse. Dò ad esempio 80% al sistema operativo, 15% job interattivi, 5% background. 

#### Esempio

Ho una coda con time slice da 8 secondi
Una seconda coda con time slice da 16 secondi
La terza ho FCFS.
Tra le tre code ho un meccanismo di priorità assoluta, cioè se un job non finisce in 8ms passa nella seconda coda. Se nella seconda non termina allora va nel first come first serve.


## Thread

Con l'interfaccia pthreads l'utente può gestire le priorità, ovviamente all'interno dello stesso processo. 


-------

Tutto questo funziona su una mono-cpu, il problema è che ora è tutto multiprocessore. Servono delle cose furbe. Ad esempio se un processo ha girato già su CPU1 lo farò girare ancora su CPU1 visto che potrebbe esserci la cache L3 ancora disponibile su quella CPU1. Questa cosa è detta affinity. 

Soft affinity: vai li, se non riesci nulla.
Hard affinity: fai tutto tutto tutto il possibile per far si che il processo vada su quella CPU. 

NUMA: non uniform memory access. Da tenere in considerazione per i sistemi distribuiti. Potrebbe essere che un host è più veloce ad accedere ad alcune aree di memoria, quindi devo trovare un equilibrio, schedulare il traffico sia su quella più "vicina" ma anche facendo loada balancing.

Stessa cosa sulle multicpu.


## Windows XP

* Pre emptive
* Time sharing (più lungo sui server Windows XP!?)
* Priorità (variabile) 31 è la massima priorità (contrariamente allo standard dove 0 è MAX)
* I processi real time hanno priorità 31-16.
* I processi 15-0 hanno priorità che può variare (un processo perde di priorità quando non è completo alla fine del time slicing, un processo guadagna priorità quando viene rimesso in esecuzione dopo che era in attesa di risorsa (priority boost)

## Linux

* Pre emptive
* Time slicing
* Priorità
* I processi real time hanno quanti temporali molto grandi, quelli background quanti molto piccoli.
* High priority 0-99 Low prio 100-139

Prima di rifare partire gli high priority della "fase" precedente devo finire i low priority.

