{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcolo delle probabilità"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il calcolo delle probabilità è la teoria che riguarda il calcolo della probabilità del verificarsi di certi eventi (elementari o composti). Il calcolo della probabilità è alla base della statistica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impostazione assiomatica\n",
    "\n",
    "Il calcolo delle probabilità che andiamo a studiare è detto ad *impostazione assiomatica* perchè basato su dei particolari assiomi dai quali si costruiscono le altre regole necessarie.\n",
    "\n",
    "### Elementi fondamentali\n",
    "\n",
    "Supponiamo di voler studiare una situazione:\n",
    "\n",
    "* $\\Omega$ è l'insieme degli esiti possibili, lo spazio campione\n",
    "* $A \\subset \\Omega$ è detto **evento**\n",
    "    * **Elementare** se $|A|=1$, altrimenti **composto**\n",
    "* Ad ogni **evento** è associata una probabilità $P(A)$\n",
    "\n",
    "Dati due eventi $A$ e $B$, questi sono **incompatibili** se sono **disgiunti**.\n",
    "\n",
    "Una misura di probabilità è un'applicazione $$P: \\mathbb{P}(\\Omega) \\to \\mathbb{R}^+_0$$ che associa un valore reale ad ogni sottoinsieme di $\\Omega$.\n",
    "\n",
    "Inoltre:\n",
    "\n",
    "* per ogni $A$, $P(A) \\geq 0$\n",
    "    * **frequenza relativa**\n",
    "* $P(\\Omega)=1$\n",
    "    * probabilità che si verifichi un qualsiasi evento\n",
    "* data la famiglia $\\{A_i,i\\in l \\subseteq N\\}$ di eventi incompatibili vale $$P(\\bigcup_{i \\in l} A_i) = \\sum_{i \\in l} P(A_i)$$\n",
    "    * la probabilità che si verifichi uno qualsiasi degli eventi appartenenti ad un insieme di eventi incompatibili è data dalla somma delle probabilità del verificarsi di ogni evento appartenente all'inseiem degli eventi incompatibili considerato\n",
    "    \n",
    "Una misura di probabilità assegna valori a **sottoinsiemi** di $\\Omega$, **non** agli eventi elementari, come si penserebbe comunemente.\n",
    "\n",
    "Ricordiamo anche le seguenti formule:\n",
    "\n",
    "* $P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$\n",
    "* $P(A \\cup B) = P(A \\cap \\bar{B}) + P(A \\cap B) + P(\\bar{A} \\cap B) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilità condizionata\n",
    "\n",
    "Dati due eventi $A,B$ con $P(B)>0$, si dice probabilità dell'evento $A$ condizionata dall'evento $B$ $$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "Deriva subito che $$P(A \\cap B) = P(A|B)P(B) = P(B|A)P(A)$$\n",
    "\n",
    "Importante è anche la formula del prodotto $$P(A \\cap B \\cap \\ldots \\cap Z) = P(A) P(B|A) \\ldots P(Z|A \\cap B \\cap \\ldots \\cap Y)$$\n",
    "\n",
    "### Indipendenza stocastica\n",
    "\n",
    "Dati due eventi $A, B$, se vale che $P(A) = P(A|B)$ e cioò anche $P(B) = P(B|A)$ e anche $P(A \\cap B) = P(A)P(B)$ essi sono **stocasticamente indipendenti**.\n",
    "\n",
    "### Formula delle probabilità totali\n",
    "\n",
    "Consideriamo una partizione $$\\{A_i,i=\\{1 \\ldots n\\} A_i \\subseteq \\Omega\\}$$ di $\\Omega$, cioè una famiglia di eventi mutualmente incompatibili, tali che la loro unione sia $\\Omega$.\n",
    "\n",
    "$$P(B) = \\sum_{i=1}^{n}P(B|A_i)P(A_i)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variabili aleatorie\n",
    "\n",
    "Le variabili alatorie sono delle \"trasformazioni\" che consentono di ricondursi sempre a $\\mathcal{R}$ come spazio campione ed a considerare come suoi sottoinsiemi gli intervalli di R.\n",
    "\n",
    "Formalmente dato uno spazio campione $\\Omega$, è detta variabilile aleatoria un'applicazione $$X: \\Omega \\to \\mathcal{R}$$ che associa un numero reale ad ogni elemento di $\\Omega$.\n",
    "\n",
    "In base a questa definizione possiamo assegnare delle probabilità agli eventi del tipo $$X \\in B \\subseteq R$$ essendo $$P(\\{X \\in B\\}) = P(\\{\\omega \\in \\Omega : X(\\omega) \\in B\\})$$\n",
    "\n",
    "Per comodità scriveremo $P(X \\in B)$\n",
    "\n",
    "Intuitivamente una variabile aleatoria può essere vista come il risultato esprimibile numericamente di un esperimento non ancora avvenuto.\n",
    "\n",
    "### Funzioni di ripartizione\n",
    "\n",
    "Ad ogni variabile aleatoria è associata una **funzione di ripartizione** $$F_X: R \\to [0,1]$$ ed indica $$F_X(t) = P(X \\leq t)$$\n",
    "\n",
    "Da questa definizione possiamo ottenere la probabilità che una variabile aleatoria assuma un intervallo tra due valori: $$P(X \\in (a,b]) = F_X(b) - F_X(a)$$\n",
    "\n",
    "Generalmente la funzione di ripartizione non è nota! E' scopo delle statistica determinarla. Nella probabilità si assume che questa sia nota.\n",
    "\n",
    "#### Requisiti di una funzione di ripartizione\n",
    "\n",
    "Una funzione di ripartizione $F$ è:\n",
    "\n",
    "* Monotona non decrescente\n",
    "* $\\lim_{t \\to \\infty} F(t) = 1$\n",
    "* $\\lim_{t \\to -\\infty} F(t) = 0$\n",
    "* $\\lim_{t \\to t_0^+} F(t) = F(t_0)$\n",
    "In [ ]:\n",
    "\n",
    "### Distribuzione discreta di probabilità\n",
    "\n",
    "Per le variabili aleatorie discere è possibile associare una funzione detta **distribuzione discreta di probabilità** $$p_X:R\\to[0,1]$$ ed è definita come segue\n",
    "\n",
    "$$p_x(t) = \\begin{cases}\n",
    "P(X = t) & \\text{per ogni } t \\in S \\\\ \n",
    "0 & \\text{altrimenti}\n",
    "\\end{cases}$$\n",
    "\n",
    "#### Requisiti funzione di distribuzione discreta di probabilità\n",
    "\n",
    "* $p_X(t) \\geq 0$ per ogni $t \\in R$\n",
    "* $\\sum p_X(s) = 1$\n",
    "\n",
    "#### Corrispondenza con funzione di ripartizione\n",
    "\n",
    "$$F_X(t) = \\sum_{s \\in S: s \\leq t} p_X(s)$$\n",
    "\n",
    "Da questa relazione ci accorgiamo che le funzione di ripartizione presentano dei salti in corrispondenza dei valori $s$, mentre sono costanti per gli altri valori.\n",
    "\n",
    "Inoltre:\n",
    "$$p_X(s) = F_X(s) - lim_{t \\to s^-} F_X(t)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Variabili Aleatorie Continue\n",
    "\n",
    "Una variabile aleatoria è detta continua nel caso in cui la corrispondente funzione di ripartizione $F_X$ sia continua. In particolare è detta **assolutamente continua** se esiste una funzione $$f_X:R \\to R_+$$ tale che $$F_X(t) = \\int^{t}_{- \\infty} f_x(u) \\, du \\text{  per ogni } t \\in R$$ \n",
    "\n",
    "Tale funzione $F_X(t)$ viene detta funzione di **densità di probabilità** di $X$. Come per le variabili aleatorie continue, questa funzione indica la probabilità che $X$ sia minore di $t$.\n",
    "\n",
    "*Per semplicità in seguito le variabili aleatoria assolutamente continue avranno sempre una funzione di ripartizione derivabile e che la densità di probabilità sia derivata di questa* \n",
    "\n",
    "E' detto **supporto** della variabile X l'insieme $S = \\{t \\in R: f_x(t) \\neq 0 \\}$ ed è l'insieme dei valori assumbili dall'evento che si sta misurando.\n",
    "\n",
    "Si osservi che se la **densità di probabilità** $f_x(t)$ di una variabile aleatoria esiste allora la **funzione di ripartizione** è una sua primitiva.\n",
    "\n",
    "La probabilità che una variabile aleatoria continua assuma un valore determinato è sempre nulla! \n",
    "\n",
    "$$P(X=t_0) = P(X \\leq t_0) - lim_{t \\to t_0} P(X \\leq t) = F_X(t_0) - lim_{t \\to t_0} F_X(t) = F_X(t_0) - F_X(t_0) = 0$$\n",
    "\n",
    "Mentre $$P(X \\in (a,b]) = F_X(b) - F_X(a) = \\int^{b}_{a} f_X(u) \\, du$$\n",
    "\n",
    "#### Requisiti funzione di densità di probabilità\n",
    "\n",
    "* $f_x(t) \\geq 0$ per ogni t\n",
    "* $\\int_{- \\infty}^{\\infty} f_x(t)dt = 1$\n",
    "\n",
    "#### Relazione tra funzione di ripartizione e densità di probabilità\n",
    "\n",
    "Data una funzione di ripartizione, si ottiene la funzione di densità di probabilità tramite la derivazione:\n",
    "\n",
    "$$\\frac{d}{dt} F_X(t) = f_X(t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variabili aleatorie multidimensionali\n",
    "\n",
    "Prendiamo l'esempio con due dimensioni. Una variabile aleatoria bidimensionale è una applicazione $$(X;Y): \\Omega \\to R^2$$ \n",
    "\n",
    "**Funzione di ripartizione congiunta** $$F_{X,Y}(t,s):R^2 \\to [0,1]$$ ed è definita come $$F_{X,Y}(t,s) = P(X \\leq t \\cap Y \\leq s)$$\n",
    "\n",
    "**Funzione di densità congiunta** $$f_{X,Y}: R^2 \\to R$$ tale che $$F_{X,Y}(t,s) = \\int^t_{- \\infty} \\int^s_{- \\infty} f_{X,Y} (u,v) \\, du \\, dv$$\n",
    "\n",
    "Valgono anche le seguenti formule:\n",
    "\n",
    "$$P((X,Y) \\in (a1,b1) \\times (a2,b2)) = F(b1,b2) - F(a1,b2) - F(b1,a2) + F(a1,a2) = \\int^{a1}_{b1} \\int^{a2}_{b2} f_{X,Y}(u,v)$$\n",
    "\n",
    "**Stocasticamente indipendenti**\n",
    "\n",
    "Se per ogni $t,s$ vale che $$F(t,s) = F(t)F(S)$$ e quindi anche $$f(t,s)=f(t)f(s)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzioni marginali\n",
    "\n",
    "### Funzione di ripartizione marginale \n",
    "\n",
    "$$F_X(t) = P(X \\leq t \\cap Y \\leq \\infty) = F_{X,Y}(t,\\infty)$$\n",
    "\n",
    "### Funzione di densità marginale \n",
    "\n",
    "$$f_x(t) = \\int^{\\infty}_{- \\infty} f_{X,Y}(t,s) ds$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indici e Variabili Aleatorie\n",
    "\n",
    "Grandezze numeriche associate alle variabili aleatorie in grado di sintetizzare, con un solo valore, le principali caratteristiche delle loro distribuzioni.\n",
    "\n",
    "### Valore atteso\n",
    "\n",
    "E' la media dei dati statistici.\n",
    "\n",
    "$$E[X] = \\begin{cases} \\sum s p_x(s) & \\text{ se X è discreta} \\\\\n",
    "\\int u \\, f_X(u) du & \\text{ se X è assolutamente continua} \\end{cases}$$\n",
    "\n",
    "Il valore atteso potrebbe non esistere! E' il caso in cui la sommatoria o l'integrale non convergano.\n",
    "\n",
    "#### Proprietà\n",
    "\n",
    "* Se $X=a$ con probabilità uguale a 1 allora $E[X]=a$\n",
    "* $E[aX+b] = a \\cdot E[X] + b$\n",
    "* Data una funzione g(X) il suo valore atteso è $\\int^{\\infty}_{-\\infty} g(u) f_X(u) du$\n",
    "\n",
    "### Momento Centrale\n",
    "\n",
    "$$E[X^r] = \\begin{cases} \\sum s^r p_x(s) & \\text{ se X è discreta} \\\\\n",
    "\\int u^r \\, f_X(u) du & \\text{ se X è assolutamente continua} \\end{cases}$$\n",
    "\n",
    "### Moda\n",
    "\n",
    "Corrisponde al valore per cui è massima la distribuzione discreta di probabilità (se X è discreta) oppure la funzione di densità (se X è ass. continua)\n",
    "\n",
    "Questo valore potrebbe non essere unico! Si parla quindi di distribuzione **multimodale**.\n",
    "\n",
    "### Mediana\n",
    "\n",
    "Data una variable aleatoria X chiamiamo mediana $X^*$ la quantità che soddisfa questa uguaglianza: \n",
    "$$\\lim_{t \\to X^*} F_X(t) \\leq 1/2 \\leq F_X(X^*)$$\n",
    "\n",
    "Nel caso di variabili discree questo è il valore per cui il valore dell'ascissa passa da un valore di 0.5 ad uno maggiore di 0.5.\n",
    "\n",
    "In generale è il valore per cui la probabilità che X assuma valori più piccoli che la probabilità che X assuma valori più grandi, sono pari a 0.5, \n",
    "\n",
    "La mediana non può essere unica, e ciè succede quando esistono più valori per cui $$F_X(t) = 1/2$$\n",
    "\n",
    "### Quantili\n",
    "\n",
    "Dato un valore $p \\in [0,1]$ è detto **quantile p-esimo** il valore $$x_p \\in R: \\lim_{t \\to x_p} F_X(t) \\leq p \\leq F_X(x_p)$$ e nel caso in cui la funzione di ripartizione sia continua allora: $$x_p = F_X(p)$$\n",
    "\n",
    "Quindi $x_p$ è il valore per cui $P(X \\leq x_p) = p$ e $P(X > x_p) = 1- p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Varianza\n",
    "\n",
    "$$V[X] = \\begin{cases}\n",
    "\\sum(s-E[X])^2 p_x(s) & \\text{se X è discreta} \\\\\n",
    "\\\\\n",
    "\\int^{\\infty}_{- \\infty} (u-E[X])^2 f_X(u) du & \\text{se X è assolutamente continua} \n",
    "\\end{cases} = \\sigma^2_X$$\n",
    "\n",
    "Proprietà:\n",
    "\n",
    "* per ogni $a$, se $X=a$, con probabilità uguale a 1, allora $V[X]=0$\n",
    "* $V[aX+b] = a^2 V[X]$\n",
    "* $V[X] = E[X^2]-(E[X])^2$\n",
    "\n",
    "### Deviazione Standard\n",
    "\n",
    "$$\\sigma_X = \\sqrt{\\sigma^2_X}$$\n",
    "\n",
    "Ha il vantaggio di avere la stessa unità di misura del valore atteso\n",
    "\n",
    "### Bidimensionali\n",
    "\n",
    "* E[XY] = E[X]E[Y]\n",
    "* V[X+Y] = V[X]+V[Y]\n",
    "\n",
    "#### Covarianza\n",
    "\n",
    "$$Cov[X,Y] = E[(X-E[X])(Y-E[Y])] = E[XY]-E[X]E[Y]$$\n",
    "\n",
    "E un indice di correlazione che sussiste tra due variabili. Tanto è più grande tanto più forte è il legame di dipendenza tra queste. \n",
    "\n",
    "Se la covarianza è 0, le variabili sono dette **incorrelate**.\n",
    "\n",
    "Dire che due variabili sono incorrelate, non implica che esse siano **indipendenti**.\n",
    "\n",
    "#### Coefficiente di Pearson\n",
    "\n",
    "$$\\mathcal{p}_{XY} = \\frac{Cov[X,Y]}{\\sqrt{V[X]V[Y]}}$$\n",
    "\n",
    "Il coefficiente è 0, se $X,Y$ sono incorrelate.\n",
    "\n",
    "$|\\mathcal{p}_{XY}|=1$ se vale che $Y=aX+b$, se vale +1, allora $a>0$, se vale -1 allora $a<0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
