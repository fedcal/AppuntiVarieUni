{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test di ipotesi non parametrici\n",
    "\n",
    "Permettono di rispondere a domande come:\n",
    "\n",
    "* Come possiamo stabilire quando una popolazione è normalmente distribuita? \n",
    "* Come possiamo fare quando non abbiamo elementi per affermare che una popolazione non è normalmente distribuita o quando siamo certi che non lo è?\n",
    "\n",
    "Vantaggi:\n",
    "\n",
    "* Utilizzabili per campioni piccoli  \n",
    "* Di più facile calcolo rispetto ai test parametrici\n",
    "\n",
    "Svantaggio:\n",
    "\n",
    "* I calcoli sono più complessi quando i campioni diventano numerosi\n",
    "* Sono meno potenti dei test parametrici\n",
    "\n",
    "## Test per la bontà di adattamento\n",
    "\n",
    "Rispondono alla domanda \"possiamo affermare che la popolazione X esaminata è distribuita secondo una specifica funzione di ripartizione F?\"\n",
    "\n",
    "Ipotesi nulla: $H_0: F_X(t) = F(t)$.\n",
    "Ipotesi alternativa: $H_1: F_X(t) \\neq F(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test di Kolmogorov-Smirov\n",
    "\n",
    "Il test di KS si basa sulla nozione di distribuzione empirica.\n",
    "\n",
    "Sia $(X_1, X_2, \\ldots, X_n)$ un campione di numerosità $n$ estratto da $X$. E' detta funzone di ripartizione empirica di $X$ la funzione \n",
    "\n",
    "$$F'_{X,n}(t) = \\frac{1}{n} \\sum U_{(-\\infty, t ]}(X_i)$$ dove \n",
    "$$ U_{(-\\infty, t ]} X_i = \n",
    "\\begin{cases}\n",
    "1 & se X_i \\in (-\\infty, t]\n",
    "0 & altrimenti\n",
    "\\end{cases}$$\n",
    "\n",
    "#### Esempio\n",
    "\n",
    "Ad esempio si suppone la serie di dati:\n",
    "\n",
    "![](images/7-01.png)\n",
    "\n",
    "La funzione empirica è sempre crescente ed a gradino. Quando $n$ cresce essa assomiglia sempre di più alla reale funzione di ripartizione della popolazione fino a coincidere con essa quando $n$ corrisponde alla numerosità dell'intera popolazione.\n",
    "\n",
    "-----\n",
    "\n",
    "Il test di KS si vasa sulla statistica\n",
    "\n",
    "$$D_n = sup|F(t) - F'_{X,n}(t)$$\n",
    "\n",
    "che specifica l'estremo superiore delle distanze in valore assoluto tra la funzione di ripartizione che vogliamo controllare come possibile per X e quella empirica ottenuta tramite il campione disponibile.\n",
    "\n",
    "$D_n$ assume valori piccoli se $H_0$ è vera, altrimenti valori grandi se $H_0$ è falsa.\n",
    "\n",
    "Per ogni ampiezza $\\alpha$ del test la regione critica risulta essere $$C = (d_{1 - \\alpha}, +1]$$ dove $d_{1 -\\ alpha}$ è il valore per cui risulta $$P(D_n \\leq d_{1 - \\alpha}) = 1 - \\alpha$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/7-02.png)\n",
    "![](images/7-03.png)\n",
    "![](images/7-04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test del chi-quadro\n",
    "\n",
    "Questo testi può essere usato senza imporre condizioni sulla $F$.\n",
    "\n",
    "Consideriamo un campione di numerorità $n$.\n",
    "\n",
    "Dividiamo il supporto di $F$ in un numero finito di intervalli che formino una partizione del supporto stesso.\n",
    "\n",
    "Denotiamo con $I_k = [t_k, t_{k+1})$ gli intervalli così ottenuti. \n",
    "\n",
    "QUi $K$ rappresenta il numero di intervalli in cui abbiamo suddiviso il supporto di $F$ mentre i valori $t$ sono gli estremi che delimitano gli intervalli. \n",
    "\n",
    "Per ogni $k = 1, \\ldots, K$ consideriamo le seguenti quantità\n",
    "\n",
    "* $n_k$ = numero di elementi $X_i$ del campione che cadono in $I_k$\n",
    "* $p_k$ = probabilità che il singolo $X_i$ cada in $I_k$ se $H_0$ è vera\n",
    "\n",
    "$$p_k = P(X \\in I_K | X \\sim F) = F(t_{k+1}) - F(t_k)$$\n",
    "\n",
    "Le quantità $n_k$ sono dette frequenze osservate degli intervalli I, mentre le $p_k$ sono dette probabilità teoriche. \n",
    "\n",
    "Notiamo che per ogni $k = 1,2, \\ldots, K$ il prodotto $np$ fornisce un numero atteso di elementi del campione che dovrebero cadere in $I_k$.\n",
    "\n",
    "Pertanto se $H_0$ è vera le differenze $n_k - np_k$ dovrebbero essere piccole in valore assoluto. \n",
    "\n",
    "$$W = \\sum^K \\frac{(n_k - np_k)^2}{np_k}$$\n",
    "\n",
    "Si può mostrare che quando $H_0$ è vera e quando le $n_k$ sono sufficientemente grandi la $W$ è approssimazione distribuita con una chi-quadro con:\n",
    "\n",
    "* K-1 gradi di libertà se la funzione di ripartizione $F$ è stata decisa arbitrariamente senza fare uso preventivo dei dati campionari\n",
    "* K-r-1 gradi di libertà se nella funzione di ripartizione F compaiono r parametri che sono stati stimati facendo uso dei dati campionari\n",
    "\n",
    "Se $W$ assume valori tropo lontani dallo zero allora rifiuteremo l'ipotesi. In particolare la regione critica di $W$ con livello di significatività $\\alpha$ risulta essere \n",
    "$$C = (+X^2_{1 - \\alpha}, +\\infty]$$ dove $$X^2_{1-\\alpha}$$ rappresenta il quantile di ordine $(1-\\alpha)$ della chi-quadro con K-1 gradi di libertà."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test per il confronto delle distribuzioni di due popolazioni\n",
    "\n",
    "$$H_0: F_X(t) = F_Y(t)$$ e $$H_1: F_X(t) \\neq F_Y(t)$$\n",
    "\n",
    "### Test dei segni\n",
    "\n",
    "Si prendono due campioni di numerosita' $n$ estratti da X e da Y. \n",
    "\n",
    "Consideriamo ogni coppia $(X_i, Y_i)$ e contiamo quante volte si verifica \n",
    "\n",
    "* $S^+$ = numero di volte che $X_i > Y_i$\n",
    "* $S^-$ = numero di volte che $X_i < Y_i$\n",
    "* $S^=$ = numero di volte che $X_i = Y_i$\n",
    "\n",
    "Se l'ipotesi nulla e' vera allora ci si aspetta che le quantita' $S^+$ ed $S^-$ siano molto simili. \n",
    "\n",
    "Infatti se l'ipotesi nulla e' vera e se $$n-S^= \\geq 10$$ la quantita' $$S_n = S^+ - S^-$$ risulta essere distribuita con $\\mu = 0$ e $\\sigma^2 = \\frac{n-S^=}{2}$.\n",
    "\n",
    "Possiamo quind definire una regione critica per $S_n$ \n",
    "\n",
    "$$C = (-\\infty, -z_{1 - \\alpha/2} \\sqrt{\\frac{n - S^=}{2}}) \\cup ( z_{1 - \\alpha/2} \\sqrt{\\frac{n - S^=}{2}}, \\infty)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dei ranghi \n",
    "\n",
    "Posso usarlo su campioni non appaiati.\n",
    "\n",
    "Siano quindi $(X_1, X_2, \\ldots, X_n)$ e $(X_1, X_2, \\ldots, Y_m)$ due campioni di numerosità $n$ ed $m$. \n",
    "\n",
    "Si prosegue in questo modo:\n",
    "\n",
    "* Si ordina in senso crescente l'insieme di tutti i dati e si associa a ciascun dato il proprio rango ovvero la posizione in cui si trova nella sistemazione in ordine crscente dei dati\n",
    "* Si sommano reparatamente i ranghi relatvi ai due campioni\n",
    "    * $R_X, R_Y$\n",
    "* Si calcolano le statistiche\n",
    "    * $U_x = n \\cdot m + \\frac{n(n+1)}{2} - R_X$\n",
    "    * $U_y = n \\cdot m + \\frac{m(m+1)}{2} - R_Y$\n",
    "    * Se i conti sono corretti allora $U_X+U_Y = n \\cdot m$\n",
    "* Si considera $U = min\\{U_Y, U_Y\\}$\n",
    "* Si può dimostrare che per $n$ ed $m$ sufficientemente grandi quando vale $H_0$ la U è approsimabile tramite una normale con parametri $\\mu_0 = \\frac{\\frac n \\cdot m}{2}$ e $\\sigma^2_U = \\frac{nm(n+m+1)}{12}$\n",
    "\n",
    "Quindi $Z_{n,m} = \\frac{U - \\mu}{\\sigma} \\sim N(0,1) $\n",
    "\n",
    "La ragione critica la si definisce come \n",
    "\n",
    "$$C = (- \\infty, -z_{1 - \\alpha/2}) \\cup (+z_{1 - \\alpha/2}, + \\infty)$$\n",
    "\n",
    "Altrimenti per $n,m > 8$ è possibile usare una tavola apposita per la regione critica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Adattamento del testi di KS\n",
    "\n",
    "Questo adattamento non richiede campioni appaiati ma lo si può usare solo quando  ci siano validi motivi per pensare che la distribuzione sia continua. \n",
    "\n",
    "Presi due campioni $X_n$ ed $Y_n$ siano $F_{X,n}$ e $F_{Y,m}$ le funzioni di ripartizione empiriche di $X$ ed $Y$ ttenute con i campioni e sia \n",
    "\n",
    "$$D_{n,m} = sup|F_{X,m}(t) - F_{Y,m}(t)|$$\n",
    "\n",
    "la statistica che specifica l'estremo supriore delle distanze tra le funzioni di ripartizione empiriche. Anche inq uesto caso si può dimostrare che quando $H_0$ è vera e quando $F_X$ è una funzione continua allora $D_{n,m}$ è indipendente dalla forma di $F_X$ ovvero ha la stessa distribuzione qualunque sia $F_X$\n",
    "\n",
    "Anche per le distribuzione della statistica campionaria $D_{n,m}$ esistono apposie tabelle. \n",
    "\n",
    "Rifiutiamo $H_0$ quando $D_{n,m}$ assume valori grandi e cade nella regione critica $$C=(d_{1 - \\alpha}, 1]$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test di indipeneza \n",
    "\n",
    "Si usa sempre il test del chi quadro per l'indipendeza.\n",
    "\n",
    "SI consideri una popolazione bidimensionale $(X,Y)$ e si supponga di poter estrarre da essa un campione causale. \n",
    "\n",
    "Si vuole controllare con livello di significatività $\\alpha$ l'ipotesi $H_0$: i caratteri sono indipendenti e $H_1$: i caratterei non sono indipendenti.\n",
    "\n",
    "Partizioniamo per prima cosa i due supporti dei caratteri $X$ ed $Y$ in un numero finito di intervalli.\n",
    "\n",
    "Denotiamo con $I^X_k$ e $I^Y_j$ gli intervalli che formano una partizione del supporto di X ed Y.\n",
    "\n",
    "Per ogni coppia $(k,j)$ consideriamo le seguenti quantità\n",
    "\n",
    "* $n^X_k =$ numero di elementi $X_i$ del campione che cadono in $I^X_k$\n",
    "* $n^Y_j =$ numero di elementi $Y_i$ del campione che cadono in $I^Y_j$\n",
    "* $n_{k,j}$ = numero di elementi $(X_i, Y_i)$ che cadono in $I^X_k \\times I^Y_j$\n",
    "* $f_k^X = \\frac{n_k^X}{n}$ = frequenza relativa di $I^X_k$\n",
    "* $f_j^Y = \\frac{n_j^Y}{n}$ = frequenza relativa di $I^Y_j$\n",
    "* $f_{k,j} = \\frac{n_{k,j}}{n}$ = frequenza relativa di $I^X_k \\times I^Y_j$\n",
    "\n",
    "Le quantità $f_{k,j}$ sono dette frequenze relative osservate. \n",
    "\n",
    "Notiamo che per ogni $(k,j)$ il prodotto $f_k^X$ \\cdot $f_j^Y$ fornisce una frequenza relativa attesa di elementi del campione che dovrebbero cadere in $I^X_k \\times I^Y_j$ se fosse vera l'ipotesi nulla $H_0$ poichè in questo caso la frequenza di ogni regione deve essere uguale al prodotto delle frequenze marginali di quella regione.\n",
    "\n",
    "Se $H_0$ è vera quindi $f_{k,j} - f_k \\cdot f_j$ dovrebber essere piccole in valore assoluto.\n",
    "\n",
    "Si considera la statistica \n",
    "\n",
    "$$W = n \\cdot \\sum^{M_x} \\sum^{M_y} \\frac{(f_{k,j} - f_k \\cdot f_j)}{f_k \\cdot f_j}$$\n",
    "\n",
    "Si può mostrare che quando l'ipotesi nulla è vera e quando le $n_{k,j}$ sono sufficientemente grandi ($\\geq 5$) allora W è approssimata con una Chi-Quadro con $(M_X - 1 ) \\cdot (M_Y - 1)$  gradi di libertà.\n",
    "\n",
    "Rifiutiamo l'ipotesi quando $W$ assume valori troppo lontani dallo zero. La regione critica risulta essere \n",
    "\n",
    "$$C = ( \\chi^2_{1-\\alpha}, infty ]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test di incorrelazione\n",
    "\n",
    "Lo si fa con una statistica che prende il nome di coefficiente di correlazione dei ranghi.\n",
    "\n",
    "Consideriamo un campione $(X_n, Y_n)$ di numerosità $n$ estratto in modo causale dalla popolazione bidimensionale $(X,Y)$\n",
    "\n",
    "Ordiniamo prima le $X_i$ e poi le $Y_i$.\n",
    "\n",
    "E' detto rango di ciascun dato la posizione che esso assume nella sequenza. \n",
    "\n",
    "Ad ogni coppia associamo il rango corrispondente.\n",
    "\n",
    "Indichiamo con $d_i$ la differenza dei ranghi $r_i^X - r_i^Y$.\n",
    "\n",
    "E' detto coefficiente di correlazione dei ranghi di spearman la statistica \n",
    "\n",
    "$$R_s = 1 - \\frac{}{6 \\cdot \\sum d^2_i}{n^3-n}$$\n",
    "\n",
    "I dati sono incorrelati quando $R_s$ è 0.\n",
    "\n",
    "Definiamo la statistica\n",
    "\n",
    "$$T_n = R_s \\cdot \\sqrt{\\frac{n-2}{1-R^2_S}}$$\n",
    "\n",
    "risulta essere distribuita con una t di Student con n-2 gradi di libertà.\n",
    "\n",
    "La regione critica risulta essere \n",
    "\n",
    "$$C = (- \\infty, -t_{1 - \\alpha/2}) \\cup (t_{1 - \\alpha/2}, \\infty)$$\n",
    "\n",
    "**Nota bene** Questo test può essere usato come alternativa al test del chi-quadro per verificare la dipendenza tra due caratteri di una popolazione. Infatti in concetto di indipendenza è più forte del concetto di incorrelazione nel senso che l'indipendenza implica l'incorrelazione.\n",
    "\n",
    "Viceversa possiamo affermare che se non sussiste incorrelazione allora non sussiste neanche l'indipendenza."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
